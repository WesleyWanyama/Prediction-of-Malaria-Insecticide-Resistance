# Prediction of Malaria Insecticide Resistance

|                       |                |
|-----------------------|----------------|
| **Student ID Number** | 136895         |
| **Student Name**      | Wesley Wanyama |
| **BBIT 4.2 Group**    | C              |

## Exploratory Data Analysis

This aims to describe and summarize the main characteristics of a dataset, helping business professionals, analysts, and decision-makers understand the data's key aspects.

### Descriptive Statistics

```{r Loading the packages}
# Install renv:
if (!is.element("renv", installed.packages()[, 1])) {
  install.packages("renv", dependencies = TRUE)
}
require("renv")
renv::init()

#Installing Language Server
if (!is.element("languageserver", installed.packages()[, 1])) {
  install.packages("languageserver", dependencies = TRUE)
}
require("languageserver")
#Installing Required Packages
if (!is.element("dplyr", installed.packages()[, 1])) {
  install.packages("dplyr", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("dplyr")

## ggplot2 - For data visualizations using the Grammar for Graphics package ----
if (!is.element("ggplot2", installed.packages()[, 1])) {
  install.packages("ggplot2", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("ggplot2")

## ggrepel - Additional options for the Grammar for Graphics package ----
if (!is.element("ggrepel", installed.packages()[, 1])) {
  install.packages("ggrepel", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("ggrepel")

## ggraph - Additional options for the Grammar for Graphics package ----
if (!is.element("ggraph", installed.packages()[, 1])) {
  install.packages("ggraph", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("ggraph")

## tidytext - For text mining ----
if (!is.element("tidytext", installed.packages()[, 1])) {
  install.packages("tidytext", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("tidytext")

## tidyr - To tidy messy data ----
if (!is.element("tidyr", installed.packages()[, 1])) {
  install.packages("tidyr", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("tidyr")

## widyr - To widen, process, and re-tidy a dataset ----
if (!is.element("widyr", installed.packages()[, 1])) {
  install.packages("widyr", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("widyr")

## gridExtra - to arrange multiple grid-based plots on a page ----
if (!is.element("gridExtra", installed.packages()[, 1])) {
  install.packages("gridExtra", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("gridExtra")

## knitr - for dynamic report generation ----
if (!is.element("knitr", installed.packages()[, 1])) {
  install.packages("knitr", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("knitr")

## kableExtra - for nicely formatted output tables ----
if (!is.element("kableExtra", installed.packages()[, 1])) {
  install.packages("kableExtra", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("kableExtra")

## circlize - To create a cord diagram or visualization ----
# by Gu et al. (2014)
if (!is.element("circlize", installed.packages()[, 1])) {
  install.packages("circlize", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("circlize")

## memery - For creating data analysis related memes ----
if (!is.element("memery", installed.packages()[, 1])) {
  install.packages("memery", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("memery")

## magick - For image processing in R ----
if (!is.element("magick", installed.packages()[, 1])) {
  install.packages("magick", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("magick")

## yarrr - To create a pirate plot ----
if (!is.element("yarrr", installed.packages()[, 1])) {
  install.packages("yarrr", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("yarrr")

## radarchart - To create interactive radar charts using ChartJS ----

if (!is.element("radarchart", installed.packages()[, 1])) {
  install.packages("radarchart", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("radarchart")

## igraph - To create ngram network diagrams ----
if (!is.element("igraph", installed.packages()[, 1])) {
  install.packages("igraph", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("igraph")

## wordcloud2 - For creating wordcloud by using 'wordcloud2.JS ----
if (!is.element("wordcloud2", installed.packages()[, 1])) {
  install.packages("wordcloud2", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("wordcloud2")

## MICE ----
# We use the MICE package to perform data imputation
if (!is.element("mice", installed.packages()[, 1])) {
  install.packages("mice", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("mice")

## Amelia ----
if (!is.element("Amelia", installed.packages()[, 1])) {
  install.packages("Amelia", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
require("Amelia")

## caret ----
if (require("caret")) {
  require("caret")
} else {
  install.packages("caret", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
# Load the caret package
library(caret)
## naivebayes ----
if (require("naivebayes")) {
  require("naivebayes")
} else {
  install.packages("naivebayes", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## LiblineaR ----
if (require("LiblineaR")) {
  require("LiblineaR")
} else {
  install.packages("LiblineaR", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## klaR ----
if (require("klaR")) {
  require("klaR")
} else {
  install.packages("klaR", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## randomForest ----
if (require("randomForest")) {
  require("randomForest")
} else {
  install.packages("randomForest", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## RRF ----
if (require("RRF")) {
  require("RRF")
} else {
  install.packages("RRF", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
## readr ----
if (require("readr")) {
  require("readr")
} else {
  install.packages("readr", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
## caretEnsemble ----
if (require("caretEnsemble")) {
  require("caretEnsemble")
} else {
  install.packages("caretEnsemble", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## C50 ----
if (require("C50")) {
  require("C50")
} else {
  install.packages("C50", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## adabag ----
if (require("adabag")) {
  require("adabag")
} else {
  install.packages("adabag", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

install.packages("moments")
install.packages("dplyr")
library(dplyr)

if (require("PreProcess")) {
  require("PreProcess")
} else {
  install.packages("PreProcess", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
library(PreProcess)
```

#### Loading the dataset

```{r Loading the dataset}
##Loading the dataset
resistance_dataset <- read.csv("data/intensity_concentration.csv")

```

```{r Measures of frequency, central tendency, distribution, and relationship}
##Measures of Frequency
resistance_dataset_freq <- resistance_dataset$RESISTANCE_INTENSITY
# Create a frequency table for the 'RESISTANCE_INTENSITY' column
frequency_table <- table(resistance_dataset_freq)
# Calculate the percentage
percentage_table <- prop.table(frequency_table) * 100
# Combine the frequency and percentage tables using cbind
result_table <- cbind(frequency = frequency_table, percentage = percentage_table)
View(result_table)

##Measures of Central Tendency
##Calculate the Mode
resistance_intensity_mode <- names(table(resistance_dataset$RESISTANCE_INTENSITY))[
  which(table(resistance_dataset$RESISTANCE_INTENSITY) == max(table(resistance_dataset$RESISTANCE_INTENSITY)))
]
print(resistance_intensity_mode)

## Measures of Distribution/Dispersion/Spread/Scatter/Variability
###Measure the distribution of the data for each variable
summary(resistance_dataset)

###Measure the standard deviation of each variable ----
selected_columns <- resistance_dataset[, 21]
selected_columns <- ifelse(is.na(selected_columns), 0, selected_columns)  # Replace NA with 0 
selected_columns <- sapply(selected_columns, as.numeric, na.rm = TRUE)
standard_deviations <- sapply(selected_columns, sd)
print(standard_deviations)

###Measure the Kurtosis of each variable
library(moments)

if (!is.element("e1071", installed.packages()[, 1])) {
  install.packages("e1071", dependencies = TRUE)
}
require("e1071")

selected_columns_filtered <- selected_columns[sapply(selected_columns, function(col) sum(!is.na(col)) >= 4)]
kurtosis <- sapply(selected_columns_filtered, kurtosis, type = 2)
print(kurtosis)

##Skewness of each variable
skewness <- sapply(selected_columns, skewness)
print(skewness)

##Inferential Statistics
###ANOVA
#resistance_dataset$TIME_HOLDING_POSTEXPOSURE <- as.numeric(as.character(resistance_dataset$TIME_HOLDING_POSTEXPOSURE))
resistance_dataset$MORTALITY_ADJUSTED <- as.numeric(as.character(resistance_dataset$MORTALITY_ADJUSTED))
```

### Basic Visualization

```{r QDA}

#Customize the Visualizations, Tables, and Colour Scheme ----
# The following defines a blue-grey colour scheme for the visualizations:
## shades of blue and shades of grey
blue_grey_colours_11 <- c("#27408E", "#304FAF", "#536CB5", "#6981c7", "#8da0db",
                          "#dde5ec", "#c8c9ca", "#B9BCC2", "#A7AAAF", "#888A8E",
                          "#636569")

blue_grey_colours_6 <- c("#27408E", "#304FAF", "#536CB5",
                         "#B9BCC2", "#A7AAAF", "#888A8E")

blue_grey_colours_4 <- c("#27408E", "#536CB5",
                         "#B9BCC2", "#888A8E")

blue_grey_colours_3 <- c("#6981c7", "#304FAF", "#888A8E")

blue_grey_colours_2 <- c("#27408E",
                         "#888A8E")

blue_grey_colours_1 <- c("#6981c7")

# Custom theme for visualizations
blue_grey_theme <- function() {
  theme(
    axis.ticks = element_line(
      linewidth = 1, linetype = "dashed",
      lineend = NULL, color = "#dfdede",
      arrow = NULL, inherit.blank = FALSE),
    axis.text = element_text(
      face = "bold", color = "#3f3f41",
      size = 12, hjust = 0.5),
    axis.title = element_text(face = "bold", color = "#3f3f41",
                              size = 14, hjust = 0.5),
    plot.title = element_text(face = "bold", color = "#3f3f41",
                              size = 16, hjust = 0.5),
    panel.grid = element_line(
      linewidth = 0.1, linetype = "dashed",
      lineend = NULL, color = "#dfdede",
      arrow = NULL, inherit.blank = FALSE),
    panel.background = element_rect(fill = "#f3eeee"),
    legend.title = element_text(face = "plain", color = "#3f3f41",
                                size = 12, hjust = 0),
    legend.position = "right"
  )
}

# Customize the text tables for consistency using HTML formatting
kable_theme <- function(dat, caption) {
  kable(dat, "html", escape = FALSE, caption = caption) %>%
    kable_styling(bootstrap_options = c("striped", "condensed", "bordered"),
                  full_width = FALSE)
}
```

### Qualitative Data Analysis

#### Removal of special characters

```{r Remove special characters}
## Special Characters and Lower Case 
remove_special_characters <- function(doc) {
  gsub("[^a-zA-Z0-9 ]", "", doc, ignore.case = TRUE)
}

# Convert INSECTICIDE_CONC to character if it's not already
resistance_dataset$INSECTICIDE_CONC <- as.character(resistance_dataset$INSECTICIDE_CONC)

# Apply the function to each element of the column
resistance_dataset$INSECTICIDE_CONC <- sapply(resistance_dataset$INSECTICIDE_CONC, remove_special_characters)

# Remove letter "g" from INSECTICIDE_CONC
resistance_dataset$INSECTICIDE_CONC <- gsub("g", "", resistance_dataset$INSECTICIDE_CONC)

# Removing the HRS and MINS from Time holding exposure column
resistance_dataset$TIME_HOLDING_POSTEXPOSURE <- as.numeric(gsub("[^0-9.]", "", resistance_dataset$TIME_HOLDING_POSTEXPOSURE))

# Data cleansing for qualitative data
resistance_dataset_new <- resistance_dataset %>%
  mutate(INSECTICIDE_INTENSITY = case_when(
    INSECTICIDE_INTENSITY == 1 ~ "Low",
    INSECTICIDE_INTENSITY == 5 ~ "Medium",
    INSECTICIDE_INTENSITY == 10 ~ "High",
    TRUE ~ as.character(INSECTICIDE_INTENSITY)  
  ))

# Convert INSECTICIDE_CONC to %
resistance_dataset_new$INSECTICIDE_CONC <- as.numeric(as.character(resistance_dataset_new$INSECTICIDE_CONC))
resistance_dataset_new$INSECTICIDE_CONC <- resistance_dataset_new$INSECTICIDE_CONC / 100

```

#### Saving the file

```{r Saving the CSV}
# Open file connection
file_conn <- file("data/resistance_dataset_new.csv", "w")

# Write data to the file
write.csv(resistance_dataset_new, file = file_conn)

# Close the file connection
close(file_conn)
```

## Preprocessing and Data Transformation

This involves finding useful features that represent the data according to the goal of addressing the problem defined. In doing so, the structure of the data and the prediction problem is exposed to data mining algorithms. Finding useful attributes/features can also be done through dimensionality reduction (identifying the most significant and uncorrelated attributes). This can be performed by a data analyst.

### Data Transformation

#### Creating subset of features

```{r Creating subset of data}
#Load the Dataset
resistance_dataset <- read.csv("data/resistance_dataset_new.csv")
resistance_dataset$MOSQUITO_NUMBER <- as.numeric(as.character(resistance_dataset$MOSQUITO_NUMBER))

#Create subset of Variables/Features
library(dplyr)

resistance_long_dataset <- dplyr::select(resistance_dataset, 
                                         ID, COUNTRY_NAME, LATITUDE, LONGITUDE, INSECTICIDE_CLASS, INSECTICIDE_CONC, INSECTICIDE_INTENSITY,
                                         INSECTICIDE_TYPE, YEAR_START, VECTOR_SPECIES, STAGE_ORIGIN, MOSQUITO_NUMBER, MORTALITY_ADJUSTED, RESISTANCE_INTENSITY)


##Select 500 random observations
rand_ind <- sample(seq_len(nrow(resistance_long_dataset)), 500)
resistance_dataset <- resistance_long_dataset[rand_ind, ]
```

#### Handling Missing Data

```{r Missing Data, message=FALSE, warning=FALSE}
# Impute the missing data
resistance_dataset_imputed <- mice::complete(mice::mice(resistance_dataset, m = 1, method = "pmm"), 1)

# Replace missing values in INSECTICIDE_INTENSITY with "Medium"
resistance_dataset_imputed$INSECTICIDE_INTENSITY <- ifelse(
  is.na(resistance_dataset_imputed$INSECTICIDE_INTENSITY),
  "Medium",
  resistance_dataset_imputed$INSECTICIDE_INTENSITY
)
```

#### Saving the file

```{# Close all open file connections}
closeAllConnections()

# Write data to CSV file
write.csv(resistance_dataset_imputed, file = "data/resistance_dataset_imputed.csv")
```

## Training the Model

This basically involves using machine learning algorithms to build predictive models based on historical data. This process is part of the broader field of predictive analytics, where the goal is to make predictions or classifications based on patterns identified in the data.

#### Data Splitting

```{r Splitting training and testing data}
resistance_dataset <- read_csv("data/resistance_dataset_imputed.csv")

str(resistance_dataset)

# Split the dataset into a 75% training set and a 25% testing set
train_index <- createDataPartition(resistance_dataset$RESISTANCE_INTENSITY,
                                   p = 0.75,
                                   list = FALSE)
resistance_dataset_train <- resistance_dataset[train_index, ]
resistance_dataset_test <- resistance_dataset[-train_index, ]
```

#### Training a Naive Bayes Classifier

```{r Naive Bayes}
##Train a Naive Bayes classifier using the training dataset ----
resistance_dataset_model_nb <-
  e1071::naiveBayes(RESISTANCE_INTENSITY ~ .,
                    data = resistance_dataset_train)
#Model summary
print(resistance_dataset_model_nb)
## 3. Test the trained model using the testing dataset ----
### 3.a. Test the trained e1071 Naive Bayes model using the testing dataset ----
predictions_nb_e1071 <-
  predict(resistance_dataset_model_nb,
          resistance_dataset_test[, c("ID", "COUNTRY_NAME", "LATITUDE", "LONGITUDE", "INSECTICIDE_CLASS",
                                     "INSECTICIDE_CONC", "INSECTICIDE_INTENSITY", "INSECTICIDE_TYPE",
                                     "YEAR_START",
                                     "VECTOR_SPECIES",
                                     "STAGE_ORIGIN", "MOSQUITO_NUMBER",
                                     "MORTALITY_ADJUSTED")])
print(predictions_nb_e1071)

#Test results using a confusion matrix ----
print(predictions_nb_e1071)

resistance_dataset_test$RESISTANCE_INTENSITY <- as.factor(resistance_dataset_test$RESISTANCE_INTENSITY)
levels(resistance_dataset_test$RESISTANCE_INTENSITY) <- levels(predictions_nb_e1071)
caret::confusionMatrix(predictions_nb_e1071,
                       resistance_dataset_test[, c("ID", "COUNTRY_NAME", "LATITUDE", "LONGITUDE", "INSECTICIDE_CLASS",
                                                  "INSECTICIDE_CONC", "INSECTICIDE_INTENSITY", "INSECTICIDE_TYPE",
                                                  "YEAR_START",
                                                  "VECTOR_SPECIES",
                                                  "STAGE_ORIGIN", "MOSQUITO_NUMBER",
                                                  "MORTALITY_ADJUSTED", "RESISTANCE_INTENSITY")]$RESISTANCE_INTENSITY)
plot(table(predictions_nb_e1071,
           resistance_dataset_test[, c("ID", "COUNTRY_NAME", "LATITUDE", "LONGITUDE", "INSECTICIDE_CLASS",
                                      "INSECTICIDE_CONC", "INSECTICIDE_INTENSITY", "INSECTICIDE_TYPE",
                                      "YEAR_START",
                                      "VECTOR_SPECIES",
                                      "STAGE_ORIGIN", "MOSQUITO_NUMBER",
                                      "MORTALITY_ADJUSTED", "RESISTANCE_INTENSITY")]$RESISTANCE_INTENSITY))
###Train an e1071::naive Bayes classifier based on the churn variable ----
resistance_dataset_model_nb <-
  e1071::naiveBayes(`RESISTANCE_INTENSITY` ~ ., data = resistance_dataset_train)

###Test the trained naive Bayes classifier using the testing dataset ----
predictions_nb_e1071 <-
  predict(resistance_dataset_model_nb, resistance_dataset_test[, 1:14])

###View a summary of the naive Bayes model and the confusion matrix ----
print(resistance_dataset_model_nb)
confusion_matrix <- caret::confusionMatrix(predictions_nb_e1071, resistance_dataset_test$RESISTANCE_INTENSITY)
```

#### More cleaning that was left out

```{r some cleaning}
# Remove rows with NAs in the target variable
resistance_dataset <- resistance_dataset[complete.cases(resistance_dataset$RESISTANCE_INTENSITY), ]
unique(resistance_dataset$RESISTANCE_INTENSITY)
resistance_dataset <- resistance_dataset[resistance_dataset$RESISTANCE_INTENSITY != "N/A", ]
# Convert 'INSECTICIDE_CONC' to numeric
resistance_dataset$INSECTICIDE_CONC <- as.numeric(resistance_dataset$INSECTICIDE_CONC)
# Convert target variable to factor 
resistance_dataset$RESISTANCE_INTENSITY <- as.factor(resistance_dataset$RESISTANCE_INTENSITY)
unique(resistance_dataset$RESISTANCE_INTENSITY)
unique(resistance_dataset$STAGE_ORIGIN)
# Exclude rows with 'NR' in the 'STAGE_ORIGIN' variable
resistance_dataset <- subset(resistance_dataset, STAGE_ORIGIN != "NR")
unique(resistance_dataset$RESISTANCE_INTENSITY)
# Remove rows with variations of 'N/A' in the outcome variable
resistance_dataset <- subset(resistance_dataset, 
                             !grepl("N/A", RESISTANCE_INTENSITY, fixed = TRUE))
unique(resistance_dataset$RESISTANCE_INTENSITY)
subset(resistance_dataset, grepl("N/A", RESISTANCE_INTENSITY, fixed = TRUE))
# Reassign levels without 'N/A'
resistance_dataset$RESISTANCE_INTENSITY <- factor(resistance_dataset$RESISTANCE_INTENSITY, levels = levels(resistance_dataset$RESISTANCE_INTENSITY)[-6])
unique(resistance_dataset$RESISTANCE_INTENSITY)
library(caret)

# Identify and remove near-zero variance variables
nzv_vars <- nearZeroVar(resistance_dataset)
resistance_dataset <- resistance_dataset[, -nzv_vars]
```

#### CART Algorithm

```{r CART}
train_control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(7)
resistance_model_cart <- train(RESISTANCE_INTENSITY ~ ., data = resistance_dataset,
                             method = "rpart", trControl = train_control)

```

#### KNN Algorithm

```{r KNN}
set.seed(7)
resistance_model_knn <- train(RESISTANCE_INTENSITY ~ ., data = resistance_dataset,
                            method = "knn", trControl = train_control)
```

#### Random Forest

```{r Random Forest}
set.seed(7)
resistance_model_rf <- train(RESISTANCE_INTENSITY ~ ., data = resistance_dataset,
                           method = "rf", trControl = train_control)
```

#### Display Model Results

```{r Results}
results <- resamples(list(CART = resistance_model_cart, KNN = resistance_model_knn,
                          RF = resistance_model_rf))
summary(results)
scales <- list(x = list(relation = "free"), y = list(relation = "free"))
bwplot(results, scales = scales)
scales <- list(x = list(relation = "free"), y = list(relation = "free"))
dotplot(results, scales = scales)
splom(results)
```

## Hyper-Parameter Tuning and Ensembles

Hyperparameter tuning and ensembles are advanced techniques in machine learning that contribute to improving model performance.

### Split Independent from Dependent Variables

```{r Split Variables}
resistance_independent_variables <- resistance_dataset[, 1:13]
resistance_dependent_variables <- resistance_dataset[, 14]
```

### Train the Model

```{r Train}
seed <- 7
metric <- "Accuracy"

train_control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(seed)
mtry <- sqrt(ncol(resistance_independent_variables))
tunegrid <- expand.grid(.mtry = mtry)
resistance_model_default_rf <- train(RESISTANCE_INTENSITY ~ ., data = resistance_dataset, method = "rf",
                                metric = metric,
                                # enables us to maintain mtry at a constant
                                tuneGrid = tunegrid,
                                trControl = train_control)
print(resistance_model_default_rf)
```

### Random Search for Best Parameter Value

```{r Random Search}
train_control <- trainControl(method = "repeatedcv", number = 10, repeats = 3,
                              search = "random")
set.seed(seed)

resistance_model_random_search_rf <- train(RESISTANCE_INTENSITY ~ ., data = resistance_dataset, method = "rf",
                                      metric = metric,
                                      # enables us to randomly search 12 options
                                      # for the value of mtry
                                      tuneLength = 12,
                                      trControl = train_control)

print(resistance_model_random_search_rf)
plot(resistance_model_random_search_rf)
```

### Manual Search for Best Parameter Value

```{r Manual Search}
train_control <- trainControl(method = "repeatedcv", number = 10,
                              repeats = 3, search = "random")

tunegrid <- expand.grid(.mtry = c(1:5))

modellist <- list()
for (ntree in c(500, 800, 1000)) {
  set.seed(seed)
  resistance_model_manual_search_rf <- train(RESISTANCE_INTENSITY ~ ., data = resistance_dataset,
                                        method = "rf", metric = metric,
                                        tuneGrid = tunegrid,
                                        trControl = train_control,
                                        ntree = ntree)
  key <- toString(ntree)
  modellist[[key]] <- resistance_model_manual_search_rf
}

# Lastly, we compare results to find which parameters gave the highest accuracy
print(modellist)

results <- resamples(modellist)
summary(results)
dotplot(results)
```

### Bagging

```{r Bagging}
train_control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
seed <- 7
metric <- "Accuracy"

## 2.a. Bagged CART ----
set.seed(seed)
resistance_model_bagged_cart <- train(RESISTANCE_INTENSITY ~ ., data = resistance_dataset, method = "treebag",
                               metric = metric,
                               trControl = train_control)

## 2.b. Random Forest ----
set.seed(seed)
resistance_model_rf <- train(RESISTANCE_INTENSITY ~ ., data = resistance_dataset, method = "rf",
                      metric = metric, trControl = train_control)

# Summarize results
bagging_results <-
  resamples(list("Bagged Decision Tree" = resistance_model_bagged_cart,
                 "Random Forest" = resistance_model_rf))

summary(bagging_results)
dotplot(bagging_results)
```

### Saving the Model

```{r Save Model}
#Saving the Model ----

## plumber ----
if (require("plumber")) {
  require("plumber")
} else {
  install.packages("plumber", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}


# Test the Model ----
# create an 80%/20% data split for training and testing datasets respectively
set.seed(9)
train_index <- createDataPartition(resistance_dataset$RESISTANCE_INTENSITY,
                                   p = 0.80, list = FALSE)
resistance_training <- resistance_dataset[train_index, ]
resistance_testing <- resistance_dataset[-train_index, ]

set.seed(9)
predictions <- predict(resistance_model_default_rf, newdata = resistance_testing)
confusionMatrix(predictions, resistance_testing$RESISTANCE_INTENSITY)


# Save and Load your Model ----
saveRDS(resistance_model_default_rf, "./models/saved_resistance_model_rf.rds")

# The saved model can then be loaded later as follows:
loaded_resistance_model_rf <- readRDS("./models/saved_resistance_model_rf.rds")
print(loaded_resistance_model_rf)

predictions_with_loaded_model <-
  predict(loaded_resistance_model_rf, newdata = resistance_testing)
confusionMatrix(predictions_with_loaded_model, resistance_testing$RESISTANCE_INTENSITY)

```
